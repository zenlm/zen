{
  "model_name": "zen-nano-thinking",
  "metadata": {
    "model_name": "zen-nano-thinking",
    "model_type": "reasoning",
    "version": "1.0.0",
    "has_thinking": true,
    "special_tokens": {
      "<s>": "bos_token",
      "</s>": "eos_token",
      "<pad>": "pad_token",
      "<thinking>": "thinking_start",
      "</thinking>": "thinking_end",
      "<|user|>": "user_token",
      "<|assistant|>": "assistant_token"
    },
    "context_length": 16384,
    "vocabulary_size": 32000,
    "hidden_size": 768,
    "num_layers": 12,
    "num_heads": 12,
    "author": "Hanzo AI",
    "license": "Apache-2.0",
    "base_model": null,
    "capabilities": [
      "reasoning",
      "chain-of-thought",
      "problem-solving"
    ],
    "training_data": "Hanzo reasoning dataset with CoT",
    "quantization_info": null
  },
  "conversion_settings": {
    "context_size": 16384,
    "vocab_type": "bpe",
    "use_f16": true,
    "quantization_options": {
      "mobile": [
        "Q4_K_S",
        "Q4_K_M"
      ],
      "balanced": [
        "Q5_K_M",
        "Q4_K_M"
      ],
      "quality": [
        "Q6_K",
        "Q8_0"
      ],
      "server": [
        "Q8_0",
        "FP16"
      ]
    }
  },
  "gguf_metadata": {
    "general.name": "zen-nano-thinking",
    "general.architecture": "reasoning",
    "general.author": "Hanzo AI",
    "general.version": "1.0.0",
    "general.license": "Apache-2.0",
    "general.description": "Zen reasoning model by Hanzo AI",
    "reasoning.context_length": 16384,
    "reasoning.embedding_length": 768,
    "reasoning.block_count": 12,
    "reasoning.attention.head_count": 12,
    "reasoning.vocabulary_size": 32000,
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.bos_token_id": 1,
    "tokenizer.ggml.eos_token_id": 2,
    "tokenizer.ggml.padding_token_id": 0,
    "tokenizer.ggml.unknown_token_id": 3,
    "general.has_thinking": "true",
    "tokenizer.special_tokens": "{\"<thinking>\": \"thinking_start\", \"</thinking>\": \"thinking_end\"}"
  }
}