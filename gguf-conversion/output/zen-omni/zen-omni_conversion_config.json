{
  "model_name": "zen-omni",
  "metadata": {
    "model_name": "zen-omni",
    "model_type": "multimodal",
    "version": "2.0.0",
    "has_thinking": false,
    "special_tokens": {
      "<s>": "bos_token",
      "</s>": "eos_token",
      "<pad>": "pad_token",
      "<|image|>": "image_start",
      "<|/image|>": "image_end",
      "<|audio|>": "audio_start",
      "<|/audio|>": "audio_end"
    },
    "context_length": 32768,
    "vocabulary_size": 50000,
    "hidden_size": 1536,
    "num_layers": 24,
    "num_heads": 16,
    "author": "Hanzo AI",
    "license": "Apache-2.0",
    "base_model": "Qwen3-VL",
    "capabilities": [
      "multimodal",
      "vision",
      "audio",
      "text"
    ],
    "training_data": "Hanzo multimodal dataset",
    "quantization_info": null
  },
  "conversion_settings": {
    "context_size": 32768,
    "vocab_type": "bpe",
    "use_f16": true,
    "quantization_options": {
      "mobile": [
        "Q4_K_S",
        "Q4_K_M"
      ],
      "balanced": [
        "Q5_K_M",
        "Q4_K_M"
      ],
      "quality": [
        "Q6_K",
        "Q8_0"
      ],
      "server": [
        "Q8_0",
        "FP16"
      ]
    }
  },
  "gguf_metadata": {
    "general.name": "zen-omni",
    "general.architecture": "multimodal",
    "general.author": "Hanzo AI",
    "general.version": "2.0.0",
    "general.license": "Apache-2.0",
    "general.description": "Zen multimodal model by Hanzo AI",
    "multimodal.context_length": 32768,
    "multimodal.embedding_length": 1536,
    "multimodal.block_count": 24,
    "multimodal.attention.head_count": 16,
    "multimodal.vocabulary_size": 50000,
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.bos_token_id": 1,
    "tokenizer.ggml.eos_token_id": 2,
    "tokenizer.ggml.padding_token_id": 0,
    "tokenizer.ggml.unknown_token_id": 3
  }
}